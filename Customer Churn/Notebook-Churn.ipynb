{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97dcb913-0106-4335-aa22-6ea3b0bfad75",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# Libraries And Their Usages\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>\n",
    "\n",
    "### Data Manipulation & Analysis\n",
    "- **numpy**: For numerical computations.\n",
    "- **pandas**: To manipulate and analyze data in tabular formats.\n",
    "\n",
    "### Data Visualization\n",
    "- **seaborn**: For creating statistical plots.\n",
    "- **matplotlib.pyplot**: For general-purpose plotting.\n",
    "- **plotly.graph_objs, plotly.express, plotly.graph_objects, plotly.subplots**: Interactive visualizations.\n",
    "- **graphviz**: Visualize decision trees.\n",
    "\n",
    "### Data Preprocessing\n",
    "- **sklearn.preprocessing**: Tools like `StandardScaler`, `OneHotEncoder`, `LabelEncoder`, and `MinMaxScaler` for scaling and encoding.\n",
    "- **sklearn.impute.SimpleImputer**: Handle missing values.\n",
    "- **sklearn.compose.ColumnTransformer**: Apply transformations on column subsets.\n",
    "\n",
    "### Feature Selection\n",
    "- **mlxtend.feature_selection.SequentialFeatureSelector**: Sequential feature selection methods.\n",
    "\n",
    "### Machine Learning Models\n",
    "- **sklearn.ensemble.RandomForestClassifier, GradientBoostingClassifier**: Ensemble learning models.\n",
    "- **sklearn.tree.DecisionTreeClassifier**: Decision tree model.\n",
    "- **sklearn.linear_model.LogisticRegression**: Logistic regression model.\n",
    "- **sklearn.neighbors.KNeighborsClassifier**: K-nearest neighbors model.\n",
    "- **xgboost.XGBClassifier**: Gradient boosting for high-performance machine learning.\n",
    "\n",
    "### Model Evaluation\n",
    "- **sklearn.metrics**: Tools for classification (e.g., `roc_auc_score`, `confusion_matrix`, `classification_report`).\n",
    "- **sklearn.model_selection**: Tools like `train_test_split`, `KFold`, `GridSearchCV`, and `RandomizedSearchCV` for model evaluation and parameter tuning.\n",
    "\n",
    "### Pipeline and Hyperparameter Optimization\n",
    "- **sklearn.pipeline.Pipeline**: Build pipelines for streamlined workflows.\n",
    "- **hyperopt**: Bayesian optimization for hyperparameter tuning.\n",
    "\n",
    "### Miscellaneous\n",
    "- **sqlite3**: SQLite database operations.\n",
    "- **folium, folium.plugins.MarkerCluster**: Interactive maps and geospatial data visualization.\n",
    "- **IPython.display**: Display images and HTML objects in notebooks.\n",
    "\n",
    "### Suppressing Warnings\n",
    "- **warnings**: Suppress unnecessary warnings during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ffc2c6-87af-4a80-81c9-e8e61772f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder,MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix ,roc_auc_score,ConfusionMatrixDisplay,accuracy_score,precision_score,recall_score,f1_score,precision_recall_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sqlite3\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from plotly.graph_objs import *\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.pipeline import Pipeline\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "import warnings\n",
    "from IPython.display import Image, display,IFrame\n",
    "from plotly.offline import plot\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59f3f4-ae25-483f-befb-d6cf36d46f24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a id='1'></a>\n",
    "# Data Exploration\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0f7ff-57bd-43c1-89f2-a3f9302d30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"churn-training.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e62a37-d8ac-464f-9131-8519b52998be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('dark_background')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"findfont: Font family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64528022-68df-4af6-a181-6183673231bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T.style.background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0fd737-3722-44dd-868b-0cd89a8750ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Info\n",
    "print(\"#\" * 50)\n",
    "print(\"DATASET INFO\")\n",
    "print(\"#\" * 50)\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "# Dataset Shape and Size\n",
    "print(\"DATASET SHAPE AND SIZE\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Shape of the dataset: {df.shape}\")\n",
    "print(f\"Size of the dataset: {df.size}\")\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "# Amount of Types\n",
    "print(\"DATA TYPES COUNT\")\n",
    "print(\"-\" * 50)\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "# Types of Features\n",
    "print(\"FEATURE DATA TYPES\")\n",
    "print(\"-\" * 50)\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "# Number of Every Item in Every Column\n",
    "print(\"VALUE COUNTS PER COLUMN\")\n",
    "print(\"-\" * 50)\n",
    "for col in df.columns:\n",
    "    print(f\"Counts of unique items in '{col}':\")\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\" + \"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f58b1-168c-4fe9-a49b-5c2964763ee0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a id='2'></a>\n",
    "# Data Cleaning\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>\n",
    "\n",
    "## Strategies:\n",
    "### 1. Null Values Checking and Imputation\n",
    "### 2. Duplicated Values Checking and Imputation\n",
    "### 3. Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44113fc4-d3fb-47b1-b3d6-052d89188938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Null Values :\n",
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe32c6-6d53-4271-9861-2d1ea1e46563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"CustomerID\",axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08773c-08f1-41ac-990d-46dae0a2c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Any Null Values If Present :\n",
    "\n",
    "df = df.dropna()\n",
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5895a81-092e-4b73-93e5-32d5b557f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated Values Check :\n",
    "duplicated_features=df.duplicated().sum()\n",
    "print(\"Number of duplicates ----->>> \",duplicated_features)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "duplicated_features=df.duplicated().sum()\n",
    "print(\"Number of duplicates of cleaning it ----->>> \",duplicated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ffbc4-3151-4042-b936-aaec517c3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Numerical Features\n",
    "features = df.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Check for Outliers in Each Feature\n",
    "print(\"#\" * 100)\n",
    "print(\"OUTLIER ANALYSIS\")\n",
    "print(\"#\" * 100)\n",
    "\n",
    "for col in features:\n",
    "    # Calculate Quartiles and IQR\n",
    "    Q1_col, Q3_col = df[col].quantile([0.25, 0.75])\n",
    "    iqr = Q3_col - Q1_col\n",
    "    low_limit = Q1_col - 1.5 * iqr\n",
    "    upper_limit = Q3_col + 1.5 * iqr\n",
    "    \n",
    "    # Identify Outliers\n",
    "    outlier = [x for x in df[col] if (x > upper_limit or x < low_limit)]\n",
    "    \n",
    "    # Display Results\n",
    "    if len(outlier) == 0:\n",
    "        print(f\"✅ No outliers in '{col}' feature.\")\n",
    "    else:\n",
    "        print(f\"❌ Outliers detected in '{col}' feature.\")\n",
    "    \n",
    "    print(f\"🔹 Q1 (25th percentile) of {col}: {Q1_col}\")\n",
    "    print(f\"🔹 Q3 (75th percentile) of {col}: {Q3_col}\")\n",
    "    print(f\"🔹 IQR (Interquartile Range): {iqr}\")\n",
    "    print(f\"🔹 Lower Limit: {low_limit}\")\n",
    "    print(f\"🔹 Upper Limit: {upper_limit}\")\n",
    "    print(f\"🔹 Outliers: {outlier}\")\n",
    "    print(f\"🔹 Number of Outliers: {len(outlier)}\")\n",
    "    print(\"-\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94b979-44b9-40e2-a973-fe27f32bd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns=[\"Age\",\"Tenure\",\"Usage Frequency\",\"Support Calls\",\"Payment Delay\",\"Total Spend\",\"Last Interaction\"]\n",
    "# for col in columns :\n",
    "#     fig2 = px.box(df, y=df[col],color='Churn', title=col + \"_Distribution\")\n",
    "#     filename=\"box.html\"\n",
    "#     plot(fig2, filename=filename, auto_open=False)\n",
    "#     display(IFrame(filename, width=800, height=600))\n",
    "#     print(\"=\"*100)\n",
    "\n",
    "## Note: File's too big cant even upload it to GitHub :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02960c9f-25a2-4c24-8e56-3a90e4c9d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Color Palette (Blue-Themed)\n",
    "color_palette = ['#1E90FF', '#00BFFF', '#4682B4', '#5F9EA0', '#87CEEB', '#6495ED']\n",
    "\n",
    "# Observation Between Age & Payment Delay\n",
    "print(\"🔹 Positive Relation:\")\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='Age', \n",
    "    y='Payment Delay', \n",
    "    color='Payment Delay', \n",
    "    color_discrete_sequence=color_palette, \n",
    "    trendline='ols'\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Age vs. Payment Delay\",\n",
    "    xaxis_title=\"Age\",\n",
    "    yaxis_title=\"Payment Delay\",\n",
    "    title_font=dict(size=16),\n",
    "    title_x=0.5\n",
    ")\n",
    "fig.show()\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Observation Between Age & Total Spend\n",
    "print(\"🔹 Negative Relation:\")\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='Age', \n",
    "    y='Total Spend', \n",
    "    color='Total Spend', \n",
    "    color_discrete_sequence=color_palette, \n",
    "    trendline='ols'\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Age vs. Total Spend\",\n",
    "    xaxis_title=\"Age\",\n",
    "    yaxis_title=\"Total Spend\",\n",
    "    title_font=dict(size=16),\n",
    "    title_x=0.5\n",
    ")\n",
    "fig.show()\n",
    "print(\"=\" * 75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a68635-066f-4831-ba0f-76fd1cf58c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the histgram:\n",
    "df.hist(figsize=(25,25),color=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cdc08-de1a-4077-b7e2-409c62b14c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram: Churn by Subscription Type\n",
    "fig = px.histogram(df, x=\"Churn\", color=\"Subscription Type\")\n",
    "fig.update_layout(\n",
    "    bargap=0.2,\n",
    "    title=\"Subscription Type vs. Churn\",\n",
    "    legend_title=\"Subscription Type\",\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Histogram: Churn by Gender\n",
    "fig = px.histogram(df, x=\"Churn\", color=\"Gender\")\n",
    "fig.update_layout(\n",
    "    bargap=0.2,\n",
    "    title=\"Gender vs. Churn\",\n",
    "    legend_title=\"Gender\",\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Histogram: Payment Delay by Contract Length\n",
    "fig = px.histogram(df, x=\"Payment Delay\", color=\"Contract Length\")\n",
    "fig.update_layout(\n",
    "    bargap=0.2,\n",
    "    title=\"Contract Length vs. Payment Delay\",\n",
    "    legend_title=\"Contract Length\",\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a1ab8-c0c9-4b37-997a-cfd88ebe96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float Data Observation\n",
    "# plt.figure(figsize=(25, 25), dpi=250)\n",
    "# sns.set(style=\"whitegrid\")\n",
    "# sns.set_palette(\"coolwarm\")\n",
    "# sns.pairplot(df.select_dtypes(\"number\"), plot_kws={'alpha': 0.6, 's': 80})\n",
    "\n",
    "# Commented so the Notebook can be uploaded to GitHub :'("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1c6a8-193a-4101-9cac-06f85c4bcac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(\"number\"):\n",
    "    if col !=\"Churn\":\n",
    "       with sns.axes_style(\"white\"):\n",
    "          sns.set(style=\"whitegrid\")\n",
    "          sns.set_palette(\"Oranges\")\n",
    "          sns.jointplot(x=df[col],y=df[\"Churn\"],kind=\"hex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543affa-4f6a-4e1b-98fd-9afce423d686",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "# Modeling\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9135294-7783-451c-bb37-a588e58faddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define All Models Used :\n",
    "\n",
    "gridsearch1=GridSearchCV(estimator=RandomForestClassifier(),             # the model used\n",
    "                        param_grid={\"n_estimators\":[50,100,160],         # Number of Decision Trees at each state\n",
    "                        \"max_depth\":[50,120,180],                        # Number of maximum depth at each state\n",
    "                        \"max_features\":[2,3,6]} ,                        # Number of features at naximum in your data\n",
    "                         cv=3,\n",
    "                         return_train_score=False,\n",
    "                         scoring='accuracy')\n",
    "\n",
    "gridsearch3=GridSearchCV(estimator=LogisticRegression(max_iter=200),\n",
    "                        param_grid = {'C': [0.1, 1, 10], 'penalty': ['l2']},\n",
    "                         cv=3,\n",
    "                         return_train_score=False,\n",
    "                         scoring='accuracy')\n",
    "\n",
    "models={\n",
    "    \"LogisticRegression\":gridsearch3,\n",
    "    \"RandomForestClassifier\":gridsearch1,\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier(max_depth=5,max_features=6,random_state=42)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007f34b-6304-4fab-a62c-2a7a2d987dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df)\n",
    "\n",
    "# Selecting Numerical Features :\n",
    "numerical_features = df.select_dtypes(include=['number'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numerical_features = scaler.fit_transform(numerical_features)\n",
    "\n",
    "# Create a DataFrame From Scaled Numerical Features\n",
    "scaled_numerical_df = pd.DataFrame(scaled_numerical_features, columns=numerical_features.columns)\n",
    "\n",
    "scaled_numerical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74caec29-7bf8-413c-88d6-00aa4ae6093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting The Data Into Train & Test :\n",
    "\n",
    "x_class,y_clss=make_classification(n_samples=100,random_state=42)\n",
    "\n",
    "x_class=scaled_numerical_df.drop(columns=\"Churn\",axis=1)\n",
    "y_class=scaled_numerical_df[\"Churn\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_class,y_class,test_size=0.3,random_state=42)\n",
    "print(\"x_train shape : \",x_train.shape)\n",
    "print(\"x_test shape : \",x_test.shape)\n",
    "print(\"y_train shape : \",y_train.shape)\n",
    "print(\"y_test shape : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd341952-256f-468e-9378-83bbe27e85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Fit the model to the training data\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test & train data\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    \n",
    "    # Calculate accuracy and mean squared error for train and test data\n",
    "    acc_train = model.score(x_train, y_train)\n",
    "    acc_test = model.score(x_test, y_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Evaluate additional metrics\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Calculate confusion matrix and classification report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    classif_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Display heatmap of the confusion matrix\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.xlabel(f\"Predicted by {model_name}\")\n",
    "    plt.ylabel(\"Truth\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Train Accuracy: {acc_train * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {acc_test * 100:.2f}%\")\n",
    "    print(f\"Train Mean Squared Error (MSE): {mse_train:.4f}\")\n",
    "    print(f\"Test Mean Squared Error (MSE): {mse_test:.4f}\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "    print(f\"AUC Score: {auc_score * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classif_report)\n",
    "    print(\"=\" * 60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d933d-231c-426a-8083-2054a59aa31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual & Prediction Values for Every Model (testing samples) :\n",
    "\n",
    "for model_name, model in models.items():\n",
    "     \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(f\"👉🏻Model: {model_name}\")\n",
    "    \n",
    "    # Create a dataframe to display actual and predicted values\n",
    "    df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "    print(df.head(10))\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41895d-546f-44f5-a10b-f4bc33d1c5d8",
   "metadata": {},
   "source": [
    "<a id='99'></a>\n",
    "## Random Forest Classifier\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcca4e9-b44a-45ae-b730-aeaadfe4def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = gridsearch1.best_estimator_\n",
    "print(\"Best estimator:\", best_estimator)\n",
    "feature_importances2 = best_estimator.feature_importances_\n",
    "feature_names = x_class.columns\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances2})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df.style.background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaaea42-c5ef-4120-91de-4a70399f037b",
   "metadata": {},
   "source": [
    "<a id='100'></a>\n",
    "## Decision Tree Classifier Feature Importances\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39b606-9365-400a-ab4a-d7374162e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_properties = {\n",
    "    'family': 'serif',\n",
    "    'color': 'blue',\n",
    "    'weight': 'bold',\n",
    "    'size': 45}\n",
    "\n",
    "decision_tree_model = models[\"DecisionTreeClassifier\"]\n",
    "plt.figure(figsize=(85,75),dpi=150)\n",
    "tree.plot_tree(decision_tree_model, filled=True, feature_names=x_class.columns, node_ids=True, fontsize=42)\n",
    "plt.title(\"Decision Tree Classifier\",fontdict=font_properties)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8016dc-64e5-4187-8fdb-de08e2e33d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances1 = decision_tree_model.feature_importances_\n",
    "feature_names = x_class.columns\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances1})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "importance_df.style.background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361d123-2ba4-4eb3-977f-efff3fc7f124",
   "metadata": {},
   "source": [
    "<a id='101'></a>\n",
    "## Logistic Regression\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9752f57-c3b1-4a12-88ac-f2db96491a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = gridsearch3.best_estimator_\n",
    "print(\"Best estimator:\", best_estimator)\n",
    "\n",
    "coefficients = best_estimator.coef_[0] # Used Coffients Of Logistic to Determine Importances\n",
    "feature_names = x_class.columns\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': coefficients})\n",
    "\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "feature_importances.style.background_gradient(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89fe372-da99-4509-93a6-5f50f2918f51",
   "metadata": {},
   "source": [
    "<a id='102'></a>\n",
    "## Saving And Load Model\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25764df5-dcb7-437c-9289-3e296660003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('RandomForestClassifier.sav', 'wb') as file:\n",
    "    pickle.dump(RandomForestClassifier, file)\n",
    "\n",
    "with open('RandomForestClassifier.sav', 'rb') as file:\n",
    "    my_object_loaded = pickle.load(file)\n",
    "print(\"Model Saved .......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a279f1c-94cc-4dca-b3aa-6e6a288d1f87",
   "metadata": {},
   "source": [
    "<a id='103'></a>\n",
    "# Summary\n",
    "<div style='border-width: 2px;\n",
    "              border-bottom-width:4px;\n",
    "              border-bottom-color:#ADD8E6;\n",
    "              border-bottom-style: solid;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3aed5-8a5f-41c0-9ccd-369aac61c359",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h4>Observation</h4>\n",
    "    First up, this notebook is all about figuring out why customers might leave a service (that's what we call \"churn\" in business speak). The next part is I really dug into the data to understand what's going on with their customers. I looked at stuff like how age relates to late payments, how much people spend, and what kind of subscriptions they have. Think of it like being a detective, looking for patterns and clues in customer behavior. I also cleaned up the data with fixing missing information and removing duplicate entries, kind of like organizing a messy drawer. \n",
    "    <br>\n",
    "    <br>\n",
    "    Here's where the cool tech stuff comes in. I used three different types of prediction models (Random Forest, Logistic Regression, and Decision Tree). I tweaked these models to work better, like fine-tuning a car engine for the best performance. I checked how well each model worked using various measurements - basically asking \"how good are you at predicting who's going to leave?\" \n",
    "    <br>\n",
    "    <br>\n",
    "    Finally, I figured out which customer characteristics are the most important in predicting whether someone will leave or stay. Each model gave its own take on what matters most. I wrapped it all up by saving their best model (the Random Forest one) so it could be used again later. It's like writing down a winning recipe - you want to keep it for future use! The whole thing is super practical, giving you both the insights into why customers leave and a tool to predict who might leave next.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623574da-8d21-4e46-9f52-8f39ed8cb18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
